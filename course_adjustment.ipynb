{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import diplib\n",
    "from PIL import ImageFilter\n",
    "import astroalign as aa\n",
    "import cv2\n",
    "import sys\n",
    "# from common_functions import qgg\n",
    "\n",
    "%run \"common_functions.py\"\n",
    "\n",
    "sys.setrecursionlimit(530000) # override needed for computing midpoints, which uses a recursive function\n",
    "Image.MAX_IMAGE_PIXELS = 366498276 # override is needed, or else it gives a DecompressionBombError\n",
    "\n",
    "# cy1_file = 'originals/ImageSLIDE4-CYCLE1.tif'\n",
    "# cy2_file = 'originals/ImageARRAY4-CYCLE2.tif'\n",
    "# cy1_shifted_file = \"originals/shiftedCycle1.tif\"\n",
    "# cy2_shifted_file = \"originals/shiftedCycle2.tif\"\n",
    "\n",
    "cy1_file = 'originals/cycle 1thnksgv.tif'\n",
    "cy2_file = 'originals/cycle 2thnksgv.tif'\n",
    "cy1_shifted_file = \"originals/shiftedcycle 1thnksgv.tif\"\n",
    "cy2_shifted_file = \"originals/shiftedcycle 2thnksgv.tif\"\n",
    "\n",
    "qgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## open tiffs\n",
    "## lower res\n",
    "\n",
    "layer_to_align = 0\n",
    "\n",
    "img_cy1 = Image.open(cy1_file)\n",
    "img_cy1.seek(layer_to_align) # navigate to brightfield\n",
    "brightfield_cy1 = np.array(img_cy1)\n",
    "brightfield_cy1 = (brightfield_cy1/256).astype('uint8') # don't need the whole range of values, so this reduces mem size, + improves access speed\n",
    "\n",
    "img_cy2 = Image.open(cy2_file)\n",
    "img_cy2.seek(layer_to_align) # navigate to brightfield\n",
    "brightfield_cy2 = np.array(img_cy2)\n",
    "brightfield_cy2 = (brightfield_cy2/256).astype('uint8') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code seeks to fix the following problem:\n",
    "# PROBLEM: the two images have different sizes, so when you attempt to scale them down, they get squished\n",
    "y_cf1, x_cf1 = brightfield_cy1.shape\n",
    "y_cf2, x_cf2 = brightfield_cy2.shape\n",
    "max_dim = max(x_cf1, x_cf2, y_cf1, y_cf2)\n",
    "\n",
    "scale_down_factor = 1 if max_dim < 3000 else round(max_dim / 3000)\n",
    "\n",
    "# used later!\n",
    "new_size = max_dim // scale_down_factor\n",
    "print(new_size)\n",
    "\n",
    "print(brightfield_cy1.shape, brightfield_cy2.shape)\n",
    "\n",
    "brightfield_cy1_padded = np.pad(brightfield_cy1, pad_width=((max_dim-y_cf1, 0), (0, max_dim-x_cf1)), mode = 'median')\n",
    "brightfield_cy2_padded = np.pad(brightfield_cy2, pad_width=((max_dim-y_cf2, 0), (0, max_dim-x_cf2)), mode = 'median')\n",
    "\n",
    "print(brightfield_cy1_padded.shape)\n",
    "\n",
    "brightfield_cy1_reduced = cv2.resize(brightfield_cy1_padded, (new_size, new_size)) # 96.5% smaller = faster\n",
    "brightfield_cy2_reduced = cv2.resize(brightfield_cy2_padded, (new_size, new_size)) # 96.5% smaller = faster\n",
    "\n",
    "### DONT DELETE!    visual\n",
    "# c_many([brightfield_cy1, resized_down ], [\"Cycle 1 (original)\", \"Cycle 1 (reduced)\"])\n",
    "\n",
    "c(brightfield_cy1_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean up\n",
    "img_cy1 = None\n",
    "img_cy2 = None\n",
    "brightfield_cy1 = None\n",
    "brightfield_cy2 = None\n",
    "brightfield_cy1_padded = None\n",
    "brightfield_cy2_padded = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bf_cy1_processed = blur_noise_reduction((brightfield_cy1_reduced))\n",
    "bf_cy1_thresholded = threshold(bf_cy1_processed, 97)\n",
    "\n",
    "\n",
    "bf_cy2_processed = blur_noise_reduction((brightfield_cy2_reduced))\n",
    "bf_cy2_thresholded = threshold(bf_cy2_processed, 97)\n",
    "\n",
    "\n",
    "\n",
    "c(bf_cy2_thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"common_functions.py\"\n",
    "\n",
    "mp, sizes, im = get_center_points(bf_cy1_thresholded.copy(), min_size=20, )\n",
    "mp2, sizes2, im2 = get_center_points(bf_cy2_thresholded.copy(), min_size=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf1_lr = lower_right(mp)\n",
    "cf1_ul = upper_left(mp)\n",
    "cf1_center = np.average([cf1_lr, cf1_ul],  axis = 0)\n",
    "print(\"original cf1 \", cf1_lr, cf1_ul)\n",
    "\n",
    "\n",
    "cf2_lr = lower_right(mp2)\n",
    "cf2_ul = upper_left(mp2)\n",
    "cf2_center = np.average([cf2_lr, cf2_ul],  axis = 0)\n",
    "print(\"original cf2 \", cf2_lr, cf2_ul)\n",
    "\n",
    "translation_cf2_to_cf1 = [cf1_center[0] - cf2_center[0],  cf1_center[1] - cf2_center[1]]\n",
    "\n",
    "print(\"\\nTRANSLATION NEEDED\", translation_cf2_to_cf1, \"\\n\")\n",
    "\n",
    "translated_cf2_lr = [cf2_lr[0] + translation_cf2_to_cf1[0], cf2_lr[1] + translation_cf2_to_cf1[1]]\n",
    "translated_cf2_ul = [cf2_ul[0] + translation_cf2_to_cf1[0], cf2_ul[1] + translation_cf2_to_cf1[1]]\n",
    "t_cf2_center = np.average([translated_cf2_lr, translated_cf2_ul],  axis = 0)\n",
    "\n",
    "print(\"translated c2\", translated_cf2_lr, translated_cf2_ul)\n",
    "print(\"and new center is\", t_cf2_center)\n",
    "\n",
    "\n",
    "### used later for the cropping:\n",
    "### the math here is basically like on the unit circle, \n",
    "### where the hyp = sqrt(2) at 45 degrees, and b = c  so a^2 = 2b^2\n",
    "### so b = sqrt( a^2/2 )\n",
    "\n",
    "cf1_width = math.sqrt ( (math.dist(cf1_ul, cf1_center)**2 / 2) )\n",
    "cf2_width = math.sqrt ( (math.dist(cf2_ul, cf1_center)**2 / 2) )\n",
    "\n",
    "\n",
    "print(cf1_width)\n",
    "print(cf2_width)\n",
    "\n",
    "### take the bigger of the two, make it an int, and add nessecary padding\n",
    "padding = 50\n",
    "FINAL_CROP_WIDTH = (int(max(cf1_width, cf2_width)) + padding) * 10\n",
    "\n",
    "\n",
    "# print(t_cf2_center)\n",
    "# image1 = cv2.line(im.copy(), cf1_ul, np.array(cf1_center).astype(\"int\"), 120, 4) \n",
    "# c(image1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t_cf2_center)\n",
    "# image2 = cv2.line(im2.copy(), cf2_lr, cf2_ul, 120, 4) \n",
    "# c(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_slope(x1, y1, x2, y2): # Line slope given two points:\n",
    "    return (y2-y1)/(x2-x1)\n",
    "\n",
    "def find_angle(s1, s2): \n",
    "    return math.degrees(math.atan((s2-s1)/(1+(s2*s1))))\n",
    "\n",
    "lineA = (t_cf2_center, translated_cf2_ul)\n",
    "lineB = (cf1_center, cf1_ul)\n",
    "\n",
    "print(lineA)\n",
    "print(lineB)\n",
    "\n",
    "slope1 = find_slope(lineA[0][0], lineA[0][1], lineA[1][0], lineA[1][1])\n",
    "slope2 = find_slope(lineB[0][0], lineB[0][1], lineB[1][0], lineB[1][1])\n",
    "\n",
    "FINAL_ANGLE = find_angle(slope1, slope2)\n",
    "print('Angle in degrees = ', FINAL_ANGLE)\n",
    "\n",
    "def rotate(origin, point, angle):\n",
    "    \"\"\"\n",
    "    Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "    The angle should be given in radians.\n",
    "    \"\"\"\n",
    "    \n",
    "    # degrees = angle\n",
    "\n",
    "    angle = angle*(math.pi/180)\n",
    "\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "    return qx, qy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c(im) # original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# \n",
    "#     THIS WARPS THE DOWNSCALED IMAGE\n",
    "# \n",
    "# ## FIRST, SHIFT\n",
    "cp = im2.copy() \n",
    "print(translation_cf2_to_cf1)\n",
    "translation_matrix = np.float32([ [1,0,translation_cf2_to_cf1[0]], [0,1,translation_cf2_to_cf1[1]] ])\n",
    "img_translation = cv2.warpAffine(cp.copy(), translation_matrix, (new_size,new_size))\n",
    "\n",
    "print(\"shift success!\")\n",
    "c(img_translation)\n",
    "\n",
    "\n",
    "\n",
    "# +----------------------------------+\n",
    "# |                                  |\n",
    "# |   New Step added Nov 29th:       |\n",
    "# |   Make two squares orthagonal.   |\n",
    "# |                                  |\n",
    "# |   This helps with the            |\n",
    "# |   micro-alignment step later.    |\n",
    "# |                                  |\n",
    "# +----------------------------------+\n",
    "\n",
    "\n",
    "lineAOrth = (lineB)\n",
    "lineBOrth = [lineB[0], lineB[0] - 400]\n",
    "\n",
    "slope1Orth = find_slope(lineAOrth[0][0], lineAOrth[0][1], lineAOrth[1][0], lineAOrth[1][1])\n",
    "slope2Orth = find_slope(lineBOrth[0][0], lineBOrth[0][1], lineBOrth[1][0], lineBOrth[1][1])\n",
    "\n",
    "angleOrth = -find_angle(slope1Orth, slope2Orth)\n",
    "\n",
    "warp_dst = im.copy()\n",
    "\n",
    "center = t_cf2_center\n",
    "\n",
    "print('Orth Angle in degrees = ', angleOrth)\n",
    "\n",
    "\n",
    "# +----------------------------------+\n",
    "\n",
    "\n",
    "## THEN, ROTATE\n",
    "warp_dst = img_translation\n",
    "\n",
    "center = t_cf2_center\n",
    "angle = -(FINAL_ANGLE + .1) + angleOrth\n",
    "print(\"angle!\", angle)\n",
    "scale = 1\n",
    "rot_mat = cv2.getRotationMatrix2D( center, angle, scale )\n",
    "print(t_cf2_center)\n",
    "warp_rotate_dst = cv2.warpAffine(warp_dst, rot_mat, (warp_dst.shape[1], warp_dst.shape[0]))\n",
    "\n",
    "c(warp_rotate_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # +----------------------------------+\n",
    "# # |                                  |\n",
    "# # |   New Step added Nov 29th:       |\n",
    "# # |   Make two squares orthagonal.   |\n",
    "# # |                                  |\n",
    "# # |   This helps with the            |\n",
    "# # |   micro-alignment step later.    |\n",
    "# # |                                  |\n",
    "# # +----------------------------------+\n",
    "\n",
    "\n",
    "# def line(p1, p2):\n",
    "#     A = (p1[1] - p2[1])\n",
    "#     B = (p2[0] - p1[0])\n",
    "#     C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "#     return A, B, -C\n",
    "\n",
    "# def intersection(L1, L2):\n",
    "#     D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "#     Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "#     Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "#     if D != 0:\n",
    "#         x = Dx / D\n",
    "#         y = Dy / D\n",
    "#         return x,y\n",
    "#     else:\n",
    "#         return False\n",
    "    \n",
    "\n",
    "\n",
    "# lineAOrth = (lineB)\n",
    "# lineBOrth = [lineB[0], lineB[0] - 400]\n",
    "\n",
    "# print(lineAOrth)\n",
    "# print(lineBOrth)\n",
    "\n",
    "# # intersection()\n",
    "\n",
    "# # slope1Orth = find_slope(lineAOrth[1][0], lineAOrth[1][1], lineAOrth[0][0], lineAOrth[0][1])\n",
    "# # slope2Orth = find_slope(lineBOrth[1][0], lineBOrth[1][1], lineBOrth[0][0], lineBOrth[0][1])\n",
    "\n",
    "# slope1Orth = find_slope(lineAOrth[0][0], lineAOrth[0][1], lineAOrth[1][0], lineAOrth[1][1])\n",
    "# slope2Orth = find_slope(lineBOrth[0][0], lineBOrth[0][1], lineBOrth[1][0], lineBOrth[1][1])\n",
    "\n",
    "# angleOrth = -  find_angle(slope1Orth, slope2Orth)\n",
    "\n",
    "# warp_dst = im.copy()\n",
    "\n",
    "\n",
    "# # c(cv2.line((warp_dst),lineAOrth[0],lineAOrth[1],(170,0,0),5) )\n",
    "# # c(cv2.line((warp_dst),lineBOrth[0],lineBOrth[1],(170,0,0),5) )\n",
    "# center = t_cf2_center\n",
    "\n",
    "# print('Angle in degrees = ', angleOrth)\n",
    "\n",
    "# scale = 1\n",
    "# rot_mat = cv2.getRotationMatrix2D( center, angleOrth, scale )\n",
    "\n",
    "# warp_rotate_dst2 = cv2.warpAffine(warp_dst, rot_mat, (warp_dst.shape[1], warp_dst.shape[0]))\n",
    "\n",
    "\n",
    "# FINAL_ANGLE = angle - angleOrth\n",
    "# print(FINAL_ANGLE)\n",
    "# c(warp_rotate_dst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#\n",
    "#     THIS WARPS THE RRREEEEEEEAAAALLLL IMAGE \n",
    "# \n",
    "###\n",
    "# open files\n",
    "bf_layer = 2 # PRESET NEEDE\n",
    "\n",
    "img_cy1 = Image.open(cy1_file)\n",
    "img_cy1.seek(bf_layer) # navigate to brightfield\n",
    "cy1_array = np.array(img_cy1)\n",
    "print(\"cy1_array before padding\", cy1_array.shape)\n",
    "\n",
    "img_cy2 = Image.open(cy2_file)\n",
    "img_cy2.seek(bf_layer) # navigate to brightfield_cy1\n",
    "cy2_array = np.array(img_cy2)\n",
    "print(\"cy2_array before padding\", cy2_array.shape)\n",
    "# end open files\n",
    "\n",
    "### PADDING STEP\n",
    "# pad image to square \n",
    "y_cf1, x_cf1 = cy1_array.shape\n",
    "y_cf2, x_cf2 = cy2_array.shape\n",
    "max_dim = max(x_cf1, x_cf2, y_cf1, y_cf2)\n",
    "\n",
    "cy1_array = np.pad(cy1_array, pad_width=((max_dim-y_cf1, 0), (0, max_dim-x_cf1)), mode = 'median')\n",
    "print(\"cy1_array after padding \", cy1_array.shape)\n",
    "\n",
    "cy2_array = np.pad(cy2_array, pad_width=((max_dim-y_cf2, 0), (0, max_dim-x_cf2)), mode = 'median')\n",
    "print(\"cy2_array after padding \", cy2_array.shape)\n",
    "### END PADDING STEP\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCALE TRANSLATION STEP\n",
    "print(scale_down_factor)\n",
    "print()\n",
    "if scale_down_factor == 1:  \n",
    "    print(\"triggered\")\n",
    "    scale_down_factor = (max_dim/new_size)\n",
    "    print(scale_down_factor)\n",
    "print(scale_down_factor)\n",
    "upscaled_translation = np.array(translation_cf2_to_cf1) * scale_down_factor\n",
    "upscaled_center = t_cf2_center * scale_down_factor\n",
    "\n",
    "\n",
    "print(\"translate from\", translation_cf2_to_cf1, \"to\", upscaled_translation)\n",
    "print(\"rotational center from\", t_cf2_center, \"to\", upscaled_center)\n",
    "print(FINAL_ANGLE)\n",
    "### END SCALE TRANSLATION STEP\n",
    "\n",
    "\n",
    "### Now shift cy2\n",
    "# translating\n",
    "translation_matrix = np.float32([ [1,0,upscaled_translation[0]], [0,1,upscaled_translation[1]] ])\n",
    "img_translation = cv2.warpAffine(cy2_array, translation_matrix, cy2_array.shape)\n",
    "\n",
    "# rotating\n",
    "rot_mat = cv2.getRotationMatrix2D( upscaled_center , -(FINAL_ANGLE + .1) + angleOrth, 1 )\n",
    "cy2_pre_crop = cv2.warpAffine(img_translation, rot_mat, (img_translation.shape[1], img_translation.shape[0]))\n",
    "cy2_cropped = cy2_pre_crop[int(upscaled_center[1] - FINAL_CROP_WIDTH):int(upscaled_center[1] +FINAL_CROP_WIDTH), \n",
    "                                   int( upscaled_center[0] - FINAL_CROP_WIDTH):int(upscaled_center[0] +FINAL_CROP_WIDTH)]\n",
    "print(cy2_cropped.shape)\n",
    "c(cy2_cropped).save(cy2_shifted_file)\n",
    "### Added Nov 29th, Nov 30th: \n",
    "### crop step, to reduce black stuff...\n",
    "\n",
    "\n",
    "## Now Shift Cy1\n",
    "\n",
    "rot_mat = cv2.getRotationMatrix2D( upscaled_center , angleOrth, 1 )\n",
    "cy1_pre_crop = cv2.warpAffine(cy1_array, rot_mat, (img_translation.shape[1], img_translation.shape[0]))\n",
    "cy1_cropped = cy1_pre_crop[int(upscaled_center[1] - FINAL_CROP_WIDTH):int(upscaled_center[1] +FINAL_CROP_WIDTH), \n",
    "                                   int( upscaled_center[0] - FINAL_CROP_WIDTH):int(upscaled_center[0] +FINAL_CROP_WIDTH)]\n",
    "print(cy1_cropped.shape)\n",
    "c(cy1_cropped).save(cy1_shifted_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(upscaled_center[1] - FINAL_CROP_WIDTH,upscaled_center[1] +FINAL_CROP_WIDTH, upscaled_center[0] - FINAL_CROP_WIDTH, upscaled_center[0] +FINAL_CROP_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#\n",
    "#        IGNORE BUT DON't DELETE... USED FOR EASY VIEWING\n",
    "# \n",
    "# ##\n",
    "\n",
    "\n",
    "img_cy1 = Image.open(cy1_shifted_file)\n",
    "brightfield_cy1 = np.array(img_cy1)\n",
    "brightfield_cy1 = (brightfield_cy1/256).astype('uint8') # don't need the whole range of values, so this reduces mem size, + improves access speed\n",
    "brightfield_cy1_reduced = cv2.resize(brightfield_cy1, (np.array(brightfield_cy1.T.shape) // 10) ) # 96.5% smaller = faster\n",
    "\n",
    "c(brightfield_cy1_reduced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
