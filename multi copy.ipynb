{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "%run \"common_functions.py\"\n",
    "\n",
    "sys.setrecursionlimit(53000) # override needed for computing midpoints, which uses a recursive function\n",
    "Image.MAX_IMAGE_PIXELS = 366498276 # override is needed, or else it gives a DecompressionBombError\n",
    "\n",
    "cy1_shifted_file = \"originals/shiftedcycle 1thnksgv.tif\"\n",
    "cy2_shifted_file = \"originals/shiftedcycle 2thnksgv.tif\"\n",
    "\n",
    "def c(img):\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "def overlay(arr1, arr2):\n",
    "    return (arr1 / 3 + arr2 / 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15640, 15640)\n"
     ]
    }
   ],
   "source": [
    "###  #  #  #  #  #  #  #  #  ###\n",
    "#                              #\n",
    "#      LOADING THE IMAGES      #\n",
    "#                              #\n",
    "###  #  #  #  #  #  #  #  #  ###\n",
    "\n",
    "layer_to_align = 2\n",
    "\n",
    "img_cy1 = Image.open(cy1_shifted_file)\n",
    "brightfield_cy1 = np.array(img_cy1)\n",
    "brightfield_cy1 = (brightfield_cy1/256).astype('uint8') # don't need the whole range of values, so this reduces mem size, + improves access speed\n",
    "\n",
    "img_cy2 = Image.open(cy2_shifted_file)\n",
    "brightfield_cy2 = np.array(img_cy2)\n",
    "brightfield_cy2 = (brightfield_cy2/256).astype('uint8') \n",
    "\n",
    "img_cy1 = None\n",
    "img_cy2 = None\n",
    "\n",
    "brightfield_cy1[brightfield_cy2 == 0] = 0\n",
    "brightfield_cy2[brightfield_cy1 == 0] = 0\n",
    "\n",
    "print(brightfield_cy2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15640, 15640)\n"
     ]
    }
   ],
   "source": [
    "###  #  #  #  #  #  #  #  #  ###\n",
    "#                              #\n",
    "# SLICING SECTION FOR ANALYSIS #\n",
    "#                              #\n",
    "###  #  #  #  #  #  #  #  #  ###\n",
    "\n",
    "START = 0\n",
    "SIZE_OF_ANALYSIS = 15640\n",
    "if brightfield_cy1.shape[0] > SIZE_OF_ANALYSIS: \n",
    "    brightfield_cy1 = brightfield_cy1[START:START+SIZE_OF_ANALYSIS, START:START+SIZE_OF_ANALYSIS]\n",
    "    brightfield_cy2 = brightfield_cy2[START:START+SIZE_OF_ANALYSIS, START:START+SIZE_OF_ANALYSIS]\n",
    "print(brightfield_cy1.shape)\n",
    "\n",
    "# c(brightfield_cy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockify(cuts):\n",
    "    \n",
    "    # Returns the center points of all the blocks in a cuts x cuts array\n",
    "    \n",
    "    centerpoints = []\n",
    "    for i in range(cuts):\n",
    "        row = []\n",
    "        for j in range(cuts):\n",
    "            # print((i + 1), cuts, (j + 1), cuts)\n",
    "            row.append(np.array([(2*i + 1) / (cuts *2), (2*j + 1) / (cuts *2)]))\n",
    "            # print((2*i + 1) / (cuts *2))\n",
    "        \n",
    "        centerpoints.append(np.array(row))\n",
    "            \n",
    "    return np.array(centerpoints)\n",
    "\n",
    "def alignImages(im1, im2):\n",
    "  # Convert images to grayscale\n",
    "  #im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "  #im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "  # Detect ORB features and compute descriptors.\n",
    "  orb = cv2.ORB_create(10000)\n",
    "  keypoints1, descriptors1 = orb.detectAndCompute(im1, None)\n",
    "  keypoints2, descriptors2 = orb.detectAndCompute(im2, None)\n",
    " \n",
    "  # Match features.\n",
    "  matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "  matches = list(matcher.match(descriptors1, descriptors2, None))\n",
    " \n",
    "  # Sort matches by score\n",
    "  matches.sort(key=lambda x: x.distance, reverse=False)\n",
    " \n",
    "  # Remove not so good matches\n",
    "  print(\"Count of Matches:\", len(matches))\n",
    "  numGoodMatches = int(len(matches) * .01)\n",
    "  print(\"Count of Good Matches:\", numGoodMatches)\n",
    "  print(\"Distance of worst match:\", matches[numGoodMatches].distance)\n",
    "  matches = matches[:numGoodMatches]\n",
    " \n",
    "  # Draw top matches\n",
    "  #imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "  #cv2.imwrite(\"matches.jpg\", imMatches)\n",
    " \n",
    "  # Extract location of good matches\n",
    "  points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "  points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    " \n",
    "  for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    " \n",
    "  # Find homography\n",
    "  h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    " \n",
    "  # Use homography\n",
    "  height, width = np.array(im2.shape) * 1.5\n",
    "  im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    " \n",
    "  return im1Reg, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  #  #  #  #  #  #  #  #  ###\n",
    "#                              #\n",
    "#          SEE CUTS!!          #\n",
    "#                              #\n",
    "###  #  #  #  #  #  #  #  #  ###\n",
    "\n",
    "\n",
    "# https://factorization.info/factors/1/factors-of-17472.html \n",
    "# the second param as below can be\n",
    "num_quads = int(brightfield_cy1.shape[0] / 550)\n",
    "\n",
    "num_quads = 3\n",
    "\n",
    "\n",
    "\n",
    "block_points = blockify(num_quads) * brightfield_cy1.shape[0]\n",
    "width = brightfield_cy1.shape[0] / 32 / 2\n",
    "# print( block_points )\n",
    "# lol = brightfield_cy2.copy()\n",
    "# for i in block_points:\n",
    "#     for j in i:\n",
    "#         # print(j)\n",
    "#         j = j.astype(int)\n",
    "        \n",
    "#         lol = cv2.circle(lol, j.astype(int), 10, 255, 10)\n",
    "#         x,y = j\n",
    "#         girth = int(block_points[1][1][0])\n",
    "#         cv2.rectangle(lol, (x-girth, y+girth), (x+girth, y-girth), (255, 255, 255), 2) \n",
    "        # print((x-girth, y-girth), (x+girth, y+girth))\n",
    "  \n",
    "# c(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'alignImages', 'c', 'cv2', 'do_', 'get_overlain', 'np', 'os', 'sys', 'time']\n"
     ]
    }
   ],
   "source": [
    "import mul\n",
    "import importlib\n",
    "importlib.reload(mul)\n",
    "\n",
    "print(dir(mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606 2606\n",
      "2606 7820\n",
      "2606 13033\n",
      "7820 2606\n",
      "7820 7820\n",
      "7820 13033\n",
      "13033 2606\n",
      "13033 7820\n",
      "13033 13033\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 49.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 49.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 41.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 54.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 52.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 46.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 48.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 53.0\n",
      "Count of Matches: 10000\n",
      "Count of Good Matches: 100\n",
      "Distance of worst match: 48.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_crew = c(np.zeros((SIZE_OF_ANALYSIS,SIZE_OF_ANALYSIS))).convert(\"RGBA\")\n",
    "\n",
    "processes = []\n",
    "import concurrent.futures\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor: \n",
    "    for i in block_points:\n",
    "        for j in i:\n",
    "            x,y = j.astype(int)\n",
    "            print(x,y)\n",
    "            # image_set = \n",
    "            processes.append(executor.submit(mul.get_overlain, brightfield_cy1[y-girth:y+girth, x- girth:x+girth,], brightfield_cy2[y-girth:y+girth, x- girth:x+girth,], x, y))\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# new_crew.save(\"nc.png\")\n",
    "\n",
    "# new_crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606 2606 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159B0ACD0>\n",
      "2606 7820 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x14846AF50>\n",
      "2606 13033 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159CD2510>\n",
      "7820 2606 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159B92E50>\n",
      "7820 7820 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159CE0690>\n",
      "7820 13033 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159B93310>\n",
      "13033 2606 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159BBABD0>\n",
      "13033 7820 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159BBB390>\n",
      "13033 13033 <PIL.Image.Image image mode=RGBA size=7818x7818 at 0x159CE3950>\n"
     ]
    }
   ],
   "source": [
    "for p in processes:\n",
    "    xy, imgAligned = p.result()\n",
    "    x, y = xy\n",
    "    print(x, y, imgAligned)\n",
    "    new_crew.paste(imgAligned,(x-girth, y-girth), imgAligned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first saved!\n",
      "145.31757616996765\n"
     ]
    }
   ],
   "source": [
    "c(brightfield_cy2).save(\"orig_3x3.png\")\n",
    "print(\"first saved!\")\n",
    "(new_crew.convert(\"L\")).save(\"shif_3x3.png\")\n",
    "\n",
    "print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
